{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test tensor flow instaliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MNIST datasets  -- example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## download data from google, dump it to data.mnist\n",
    "mnist= input_data.read_data_sets('data/mnist/',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### take a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe25ed456d8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe25ed88240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## take a look at our train data \n",
    "## each row is a flattened image\n",
    "print(mnist.train.images.shape)\n",
    "## take a look at an image\n",
    "i = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(i,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## take a look at the labels for the picture\n",
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set up some paramaters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set up learning rate --- how fast you want it to learn \n",
    "learning_rate = 0.001    ## how big of a jump you want to take while optimizing\n",
    "training_epochs = 25     ## how many training cycles you want to go through \n",
    "batch_size = 100         ## batch size\n",
    "\n",
    "## shape you network layers \n",
    "n_classes = 10                        ## we have 0 - 9 numbers to be recognized \n",
    "n_samples = mnist.train.num_examples  ## training sample \n",
    "n_input = 784                         ## number of features, it is the size of our image pixels \n",
    "\n",
    "## set up your layers \n",
    "n_hidden_1 = 256                      ## 256 is commonly used for images, it is just the way computer saves colors \n",
    "n_hidden_2 = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights \n",
    "    biases: dict of bias values  ---------- errors \n",
    "    '''\n",
    "    # Fisrt Hidden Layer with RELU Activation\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # Func(X * W + B) = RELU  -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output Layer \n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### initiate random weights and biases\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden_1])),     # here, it is a 55000 by 256 matrix for initiation\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),   # here, it is a 256 by 256 matrix for initiation\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),     # here, it is a 55000 by 256 matrix for initiation\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),   # here, it is a 256 by 256 matrix for initiation\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## set two place holder for x and y \n",
    "x = tf.placeholder('float',[None,n_input])              # training place holder\n",
    "y = tf.placeholder('float',[None,n_classes])            # result place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## set up cost function and optimization function \n",
    "pred = multilayer_perceptron(x,weights,biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### launch a interactive session, and do things interactively \n",
    "### in production, you do not that interactive session \n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "## initiate a session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 cost:47.2085\n",
      "Epoch:2 cost:29.2690\n",
      "Epoch:3 cost:20.1834\n",
      "Epoch:4 cost:14.8160\n",
      "Epoch:5 cost:10.9753\n",
      "Epoch:6 cost:8.4736\n",
      "Epoch:7 cost:6.4503\n",
      "Epoch:8 cost:4.8048\n",
      "Epoch:9 cost:3.6390\n",
      "Epoch:10 cost:2.8173\n",
      "Epoch:11 cost:2.0970\n",
      "Epoch:12 cost:1.6535\n",
      "Epoch:13 cost:1.3141\n",
      "Epoch:14 cost:1.0210\n",
      "Epoch:15 cost:0.7544\n",
      "Epoch:16 cost:0.7022\n",
      "Epoch:17 cost:0.6474\n",
      "Epoch:18 cost:0.6115\n",
      "Epoch:19 cost:0.4512\n",
      "Epoch:20 cost:0.4913\n",
      "Epoch:21 cost:0.4531\n",
      "Epoch:22 cost:0.5117\n",
      "Epoch:23 cost:0.4027\n",
      "Epoch:24 cost:0.3098\n",
      "Epoch:25 cost:0.3705\n",
      "Epoch:26 cost:0.3563\n",
      "Epoch:27 cost:0.3495\n",
      "Epoch:28 cost:0.2758\n",
      "Epoch:29 cost:0.3348\n",
      "Epoch:30 cost:0.2968\n",
      "Epoch:31 cost:0.3009\n",
      "Epoch:32 cost:0.3100\n",
      "Epoch:33 cost:0.1985\n",
      "Epoch:34 cost:0.2988\n",
      "Epoch:35 cost:0.2888\n",
      "Epoch:36 cost:0.2661\n",
      "Epoch:37 cost:0.2052\n",
      "Epoch:38 cost:0.2456\n",
      "Epoch:39 cost:0.1996\n",
      "Epoch:40 cost:0.2191\n",
      "Epoch:41 cost:0.1595\n",
      "Epoch:42 cost:0.2796\n",
      "Epoch:43 cost:0.1723\n",
      "Epoch:44 cost:0.1942\n",
      "Epoch:45 cost:0.1933\n",
      "Epoch:46 cost:0.2090\n",
      "Epoch:47 cost:0.1750\n",
      "Epoch:48 cost:0.1901\n",
      "Epoch:49 cost:0.2111\n",
      "Epoch:50 cost:0.1974\n",
      "Epoch:51 cost:0.1997\n",
      "Epoch:52 cost:0.1873\n",
      "Epoch:53 cost:0.1489\n",
      "Epoch:54 cost:0.1651\n",
      "Epoch:55 cost:0.1454\n",
      "Epoch:56 cost:0.1980\n",
      "Epoch:57 cost:0.2072\n",
      "Epoch:58 cost:0.1580\n",
      "Epoch:59 cost:0.1379\n",
      "Epoch:60 cost:0.1599\n",
      "Epoch:61 cost:0.1625\n",
      "Epoch:62 cost:0.1329\n",
      "Epoch:63 cost:0.1357\n",
      "Epoch:64 cost:0.1895\n",
      "Epoch:65 cost:0.1339\n",
      "Epoch:66 cost:0.1096\n",
      "Epoch:67 cost:0.1517\n",
      "Epoch:68 cost:0.1719\n",
      "Epoch:69 cost:0.1021\n",
      "Epoch:70 cost:0.1299\n",
      "Epoch:71 cost:0.2018\n",
      "Epoch:72 cost:0.1811\n",
      "Epoch:73 cost:0.0961\n",
      "Epoch:74 cost:0.1580\n",
      "Epoch:75 cost:0.1219\n",
      "Epoch:76 cost:0.1245\n",
      "Epoch:77 cost:0.1064\n",
      "Epoch:78 cost:0.1386\n",
      "Epoch:79 cost:0.1315\n",
      "Epoch:80 cost:0.1371\n",
      "Epoch:81 cost:0.1186\n",
      "Epoch:82 cost:0.1212\n",
      "Epoch:83 cost:0.1186\n",
      "Epoch:84 cost:0.0720\n",
      "Epoch:85 cost:0.1481\n",
      "Epoch:86 cost:0.1265\n",
      "Epoch:87 cost:0.0899\n",
      "Epoch:88 cost:0.1898\n",
      "Epoch:89 cost:0.0880\n",
      "Epoch:90 cost:0.0925\n",
      "Epoch:91 cost:0.1297\n",
      "Epoch:92 cost:0.1148\n",
      "Epoch:93 cost:0.0942\n",
      "Epoch:94 cost:0.0609\n",
      "Epoch:95 cost:0.1300\n",
      "Epoch:96 cost:0.1212\n",
      "Epoch:97 cost:0.1082\n",
      "Epoch:98 cost:0.1192\n",
      "Epoch:99 cost:0.1163\n",
      "Epoch:100 cost:0.0878\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "## 15 loops  -- in real world, you will probably run thousands of iterations\n",
    "for epoch in range(training_epochs):  #training_epochs\n",
    "    #Cost \n",
    "    avg_cost = 0.0                           # set initial cost to be 0\n",
    "    total_batch = int(n_samples/batch_size)   # calculate number of batches \n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)                ## get training x and y from mnist data, for each batch \n",
    "        \n",
    "        _,c = sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})   ## get the cost after 1 iteration \n",
    "        avg_cost += c/total_batch                                          ## add up cost for each batch \n",
    "    print(\"Epoch:{} cost:{:.4f}\".format(epoch+1,avg_cost))\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## tf.equal() basicall check if x=y\n",
    "## pred is essentially out output layer, which is our predictions \n",
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))    ## returns a tf boolean array of correct predictions\n",
    "correct_predictions = tf.cast(correct_predictions,'float')\n",
    "accuracy = tf.reduce_mean(correct_predictions)                      ## get the mean of the o,1 array, which is the accuracy\n",
    "#### this accuracy is still a tf object, we can pass test data into it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96619999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pass in test data and get the accuracy \n",
    "accuracy.eval({x:mnist.test.images,y:mnist.test.labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
